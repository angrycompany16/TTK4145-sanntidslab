{
	"nodes":[
		{"id":"d136597d0a709f14","type":"text","text":"# How to decide if busy?\n- Is the request in the same direction as me? \n- Am I idle?","x":880,"y":1920,"width":540,"height":423},
		{"id":"863c1e1a6427c6cf","type":"text","text":"# Peer 1\nAny requests that were being made to peer 2 will now instead be made to peer 3, and so on so forth. This may lead to a request being taken by multiple elevators, but is this a problem? This is not a catastrophic error","x":1893,"y":2890,"width":387,"height":311},
		{"id":"a37f5c843fbc4c88","type":"text","text":"# Peer 2\nWill have local Requests data, service all these. Also service hall calls, essentially run as usual except no requests will be coming in.\nAlso try to reconnect to the network at an even interval","x":2520,"y":2890,"width":420,"height":311},
		{"id":"22425a8b174b2fd5","type":"text","text":"# Reconnecting nodes\nWhen reconnecting (Or connecting) the node needs to set up a connection with every other node in the network. It works as follows\n1. Broadcast the \"I'm alive\" message over the network\n2. Everyone reads the broadcast message and adds Peer x to their list of peers, if Peer x is not already there. No confirmation needed, everyone is constantly telling everyone else that they are on the network","x":2200,"y":3240,"width":400,"height":420},
		{"id":"819244b5d8f4803b","type":"text","text":"# Disconnect behaviour\nEvery peer broadcasts a \"I'm alive\" message on the network\nEvery peer also checks for the aliveness of other peers\nIf one peer is not alive, do not Request that it takes calls","x":2200,"y":2475,"width":400,"height":378},
		{"id":"be762a91d47661af","type":"text","text":"# Button lights\n- Actually easy\n- Button lights are set based on what is read on the peer data broadcast\n- If a peer broadcasts that it is going to take a call, we can consider this to be a guarantee. Thus it is fine to light up the buttons.","x":1580,"y":3240,"width":440,"height":420},
		{"id":"40795910debc9360","type":"text","text":"# Peer 1\nPeer 2 will disconnect, so peer 1 loses sight of it. However, it keeps broadcasting the data of how peer 2 looked the last time it was seen.","x":3053,"y":2890,"width":387,"height":311},
		{"id":"279a2fbbc2b19c98","type":"text","text":"# Peer 2\nRestarts. On initializing, read the state from the network messages. If this is the initialization of the whole network, the data being broadcasted will default to \"0\"-data.","x":3680,"y":2890,"width":420,"height":311},
		{"id":"15987744a7c8390a","type":"text","text":"# Failure behaviour\nImportant principle: \"Sometimes the best solution is just to kill yourself\"\nI.E. the primary failure behaviour is to restart. This means that a failure will always imply disconnecting from the network\nCalls being restored even in the case of a crash means that the data must be stored somewhere else.\nIn the \"I'm alive\" message, information about every other peer is also included.\nIn the case of a failure, when reconnecting, the peer reads the information that the other nodes are distributing about itself, and can thus pick up the calls that have been lost.","x":3360,"y":2320,"width":400,"height":533},
		{"id":"14ba5e63994454a5","type":"text","text":"# The cab request\nSender IpAddr\n\nRequest info (floor etc.)","x":1474,"y":1920,"width":419,"height":423},
		{"id":"447c96bc1b32bebd","type":"text","text":"# The \"I'm alive\" message\nSenderIp\nMyState // Takes authority\nElevatorState[] peerStates // Only includes hall calls","x":1954,"y":1920,"width":486,"height":423},
		{"id":"a8c6207d9c716eec","type":"text","text":"# Node 2\nnodes []Node","x":1700,"y":4500,"width":250,"height":145},
		{"id":"dbe250620a99797a","type":"text","text":"# Node 1\nnodes []Node","x":1380,"y":4500,"width":255,"height":145},
		{"id":"b233a7659aeb6da9","type":"text","text":"# Node 3\nnodes []Node","x":1540,"y":4700,"width":250,"height":145},
		{"id":"4922e102ab0aaee3","type":"text","text":"# Alive message\nSenderIp IpAddress\nNetworkState []NodeState // Perceived state of every other node","x":2345,"y":4360,"width":366,"height":160},
		{"id":"f4da95f68608e579","type":"text","text":"# Node 2\nnodes []Node","x":2841,"y":4640,"width":255,"height":145},
		{"id":"f8a541c7e5fdf056","type":"text","text":"# Node 1\nnodes []Node","x":2401,"y":4640,"width":255,"height":145},
		{"id":"06ec04552a1396c8","type":"text","text":"# Broadcast","x":2403,"y":4160,"width":250,"height":60},
		{"id":"1dbf1bcbc9e14d70","type":"text","text":"# Peer 2\nBusy","x":1220,"y":2593,"width":329,"height":170},
		{"id":"dee27e536c4a201f","type":"text","text":"# Peer 4\nFree","x":1220,"y":2763,"width":329,"height":180},
		{"id":"3735115bbd2155d5","type":"text","text":"# Peer 3\nFree => Accept call\n- Service the request \n- Send acknowledge","x":1220,"y":2943,"width":329,"height":336},
		{"id":"5aa105245882f0c1","type":"text","text":"# Peer 1\nNote: Prioritizes other peers over itself\n\nPeer 2:\nCan connect to TCP, sends (busy) signal\n\nPeer 4:\nUnable to connect via TCP, skips\n\nPeer 3:\nSuccessfully connects, accepts request and sends acknowledge","x":320,"y":2651,"width":396,"height":405},
		{"id":"0277cd37f21bffd6","type":"text","text":"Elevator disconnects","x":2840,"y":1280,"width":250,"height":60},
		{"id":"2fd6ef08a0eaf379","type":"text","text":"Elevator crashes","x":2460,"y":1280,"width":250,"height":60},
		{"id":"42bbd39bf31360de","type":"text","text":"Startup\n- Make backup\n- Read cab calls and hall calls","x":2460,"y":1460,"width":250,"height":160},
		{"id":"922ce78752d00046","type":"text","text":"- Consistency in shared state (the final touch)?\n- \"Cab-calls all nodes reflect back each nodes cab calls. Great, this is also btw. what you do with the hall orders when you think about it. But this way of looking at it is the p2p way. The primary-backup way would be to let the primary know about the cab calls, and then give them to you when you are ready.\"","x":2780,"y":1778,"width":420,"height":302},
		{"id":"9f8e9f2588f99eb4","type":"text","text":"Network","x":-221,"y":3348,"width":250,"height":60},
		{"id":"1411d43913cd79f5","type":"text","text":"Elevator disconnects","x":2120,"y":1140,"width":250,"height":60},
		{"id":"0cc94a2c81563b41","type":"text","text":"Elevator crashes","x":1740,"y":1140,"width":250,"height":60},
		{"id":"70e1a8ce9011dfdd","type":"text","text":"Startup\n- Make backup\n- Read cab calls","x":1740,"y":1310,"width":250,"height":160},
		{"id":"8bb0565ffdcdb731","type":"text","text":"Connect","x":2120,"y":1590,"width":250,"height":60},
		{"id":"c46ee07a8fc50266","type":"text","text":"Translate elevator algorithms","x":-96,"y":3460,"width":265,"height":85},
		{"id":"caba4a5134622d65","type":"text","text":"Primary backup","x":44,"y":3348,"width":250,"height":60},
		{"id":"b0093f34c7979962","type":"text","text":"# How to decide if busy?\n- Is the request in the same direction as me? \n- Am I idle?","x":5845,"y":3452,"width":540,"height":423},
		{"id":"69a7302eee11627d","type":"text","text":"# Peer 1\nAny requests that were being made to peer 2 will now instead be made to peer 3, and so on so forth. This may lead to a request being taken by multiple elevators, but is this a problem? This is not a catastrophic error","x":6858,"y":4422,"width":387,"height":311},
		{"id":"df15fa127fc1f609","type":"text","text":"# Peer 2\nWill have local Requests data, service all these. Also service hall calls, essentially run as usual except no requests will be coming in.\nAlso try to reconnect to the network at an even interval","x":7485,"y":4422,"width":420,"height":311},
		{"id":"9526764aad53c882","type":"text","text":"# Reconnecting nodes\nWhen reconnecting (Or connecting) the node needs to set up a connection with every other node in the network. It works as follows\n1. Broadcast the \"I'm alive\" message over the network\n2. Everyone reads the broadcast message and adds Peer x to their list of peers, if Peer x is not already there. No confirmation needed, everyone is constantly telling everyone else that they are on the network","x":7165,"y":4772,"width":400,"height":420},
		{"id":"aad3a215a6fb9acf","type":"text","text":"# Disconnect behaviour\nEvery peer broadcasts a \"I'm alive\" message on the network\nEvery peer also checks for the aliveness of other peers\nIf one peer is not alive, do not Request that it takes calls","x":7165,"y":4007,"width":400,"height":378},
		{"id":"25e709df0ba07a63","type":"text","text":"# Button lights\n- Actually easy\n- Button lights are set based on what is read on the peer data broadcast\n- If a peer broadcasts that it is going to take a call, we can consider this to be a guarantee. Thus it is fine to light up the buttons.","x":6545,"y":4772,"width":440,"height":420},
		{"id":"1137a518da71369d","type":"text","text":"# Peer 1\nPeer 2 will disconnect, so peer 1 loses sight of it. However, it keeps broadcasting the data of how peer 2 looked the last time it was seen.","x":8018,"y":4422,"width":387,"height":311},
		{"id":"1699ac8580e4fe9c","type":"text","text":"# Peer 2\nRestarts. On initializing, read the state from the network messages. If this is the initialization of the whole network, the data being broadcasted will default to \"0\"-data.","x":8645,"y":4422,"width":420,"height":311},
		{"id":"1e8debca1573d1e2","type":"text","text":"# Failure behaviour\nImportant principle: \"Sometimes the best solution is just to kill yourself\"\nI.E. the primary failure behaviour is to restart. This means that a failure will always imply disconnecting from the network\nCalls being restored even in the case of a crash means that the data must be stored somewhere else.\nIn the \"I'm alive\" message, information about every other peer is also included.\nIn the case of a failure, when reconnecting, the peer reads the information that the other nodes are distributing about itself, and can thus pick up the calls that have been lost.","x":8325,"y":3852,"width":400,"height":533},
		{"id":"ebd69f31d7f021f5","type":"text","text":"# The cab request\nSender IpAddr\n\nRequest info (floor etc.)","x":6439,"y":3452,"width":419,"height":423},
		{"id":"f72b01a2f7322368","type":"text","text":"# The \"I'm alive\" message\nSenderIp\nMyState // Takes authority\nElevatorState[] peerStates // Only includes hall calls","x":6919,"y":3452,"width":486,"height":423},
		{"id":"7960fac0dd8f6e44","type":"text","text":"# Node 2\nnodes []Node","x":6665,"y":6032,"width":250,"height":145},
		{"id":"b88209e3ccab92ec","type":"text","text":"# Node 1\nnodes []Node","x":6345,"y":6032,"width":255,"height":145},
		{"id":"913aa654aa19fb6e","type":"text","text":"# Node 3\nnodes []Node","x":6505,"y":6232,"width":250,"height":145},
		{"id":"60c4c1f763ae68ed","type":"text","text":"# Alive message\nSenderIp IpAddress\nNetworkState []NodeState // Perceived state of every other node","x":7310,"y":5892,"width":366,"height":160},
		{"id":"e25fd5be01c972eb","type":"text","text":"# Node 2\nnodes []Node","x":7806,"y":6172,"width":255,"height":145},
		{"id":"8567620b43b17893","type":"text","text":"# Node 1\nnodes []Node","x":7366,"y":6172,"width":255,"height":145},
		{"id":"03e41908a4234a94","type":"text","text":"# Broadcast","x":7368,"y":5692,"width":250,"height":60},
		{"id":"234d4aa4eb13fc73","type":"text","text":"# Peer 2\nBusy","x":6185,"y":4125,"width":329,"height":170},
		{"id":"5e2768ae5ec70e72","type":"text","text":"# Peer 3\nFree","x":6185,"y":4295,"width":329,"height":180},
		{"id":"cc5427e78474255e","type":"text","text":"# Peer 4\nFree => Accept call\n- Service the request \n- Send acknowledge","x":6185,"y":4475,"width":329,"height":336},
		{"id":"ebb2525c8336be83","type":"text","text":"# Peer 1\nPeer 2:\nCan connect to TCP, sends (busy) signal\n\nPeer 4:\nUnable to connect via TCP, skips\n\nPeer 3:\nSuccessfully connects, accepts request and sends acknowledge","x":5285,"y":4183,"width":396,"height":405},
		{"id":"5e9e9fc805e7772e","type":"text","text":"- Consistency in shared state (the final touch)?\n- \"Cab-calls all nodes reflect back each nodes cab calls. Great, this is also btw. what you do with the hall orders when you think about it. But this way of looking at it is the p2p way. \n- The primary-backup way would be to let the primary know about the cab calls, and then give them to you when you are ready.\"","x":7745,"y":3310,"width":420,"height":354},
		{"id":"eb55ede8be95bde6","type":"text","text":"Crossroads:\n- Backup sirkel-struktur *eller* floating backup (Hvilken er best [i test]?)\n- ","x":5285,"y":4858,"width":396,"height":334},
		{"id":"90e29b70edb1ecfe","type":"text","text":"Forskjell TCP UDP:\n- UDP bryr seg kun om nyeste melding\n- Via TCP kan man aksessere gamle meldinger og kan bevare ordering etc.","x":5740,"y":4858,"width":400,"height":334},
		{"id":"1db775cf6ee470ba","type":"text","text":"Conventions:\n- Stack traced errors - go-errors/errors\n- Testable code in some way\n\t- main.go testing\n\t- returning errors is default error handling mode","x":4805,"y":4858,"width":375,"height":334},
		{"id":"c0d5014e4aba26b1","type":"text","text":"Til neste gang:\nSette opp simulator\nish ferdig kode","x":4380,"y":4896,"width":312,"height":259},
		{"id":"999c1aa77c9938a5","x":6200,"y":1720,"width":731,"height":388,"type":"text","text":"Backup current problem:\n\n\nHva er feilhåndtering når man DC'er:\n- ta over ordre med en gang \n\t- Effektiv (ved død), men potensielt mange doble utføringer (ved bare DC)\n\n!Hvordan skal vi detektere at to heiser deler mange ordre\n\n- Fullfør egne ordre først (en heis som har DC er feilfri)\n\t- Ueffektiv ved død (men potensielt mindre dobbel utføring ved DC) \n\n!Hvordan skal vi gi tilbake ordre (vil vi gjøre dette eller ikke)\n\n\nBurde utvide request struct med ID, da kan man eventuelt slette requests som gjøres av flere heiser unikt.\n"}
	],
	"edges":[
		{"id":"85082dc472fc5ab3","fromNode":"5aa105245882f0c1","fromSide":"right","toNode":"1dbf1bcbc9e14d70","toSide":"left","label":"TCP connection"},
		{"id":"8edea861ee9c34c6","fromNode":"5aa105245882f0c1","fromSide":"right","toNode":"3735115bbd2155d5","toSide":"left","label":"Connection success"},
		{"id":"3b8abba5a41a7430","fromNode":"5aa105245882f0c1","fromSide":"right","toNode":"dee27e536c4a201f","toSide":"left","label":"Connection fail"},
		{"id":"cd3c9c49b4e3c152","fromNode":"863c1e1a6427c6cf","fromSide":"right","toNode":"a37f5c843fbc4c88","toSide":"left","label":"Disconnected"},
		{"id":"89a7ed0227653ae6","fromNode":"40795910debc9360","fromSide":"right","toNode":"279a2fbbc2b19c98","toSide":"left","label":"Crashed"},
		{"id":"24e5b813b5979152","fromNode":"dbe250620a99797a","fromSide":"bottom","toNode":"b233a7659aeb6da9","toSide":"top"},
		{"id":"a1903b44bb11a993","fromNode":"dbe250620a99797a","fromSide":"right","toNode":"a8c6207d9c716eec","toSide":"left"},
		{"id":"280eef602a0fbf0a","fromNode":"a8c6207d9c716eec","fromSide":"left","toNode":"dbe250620a99797a","toSide":"right"},
		{"id":"f0a283230a8c4795","fromNode":"b233a7659aeb6da9","fromSide":"top","toNode":"dbe250620a99797a","toSide":"bottom"},
		{"id":"f97bae355dd5809e","fromNode":"b233a7659aeb6da9","fromSide":"top","toNode":"a8c6207d9c716eec","toSide":"bottom"},
		{"id":"e22b916e96c30b96","fromNode":"a8c6207d9c716eec","fromSide":"bottom","toNode":"b233a7659aeb6da9","toSide":"top"},
		{"id":"29b891ee9ebd68bc","fromNode":"f8a541c7e5fdf056","fromSide":"top","toNode":"4922e102ab0aaee3","toSide":"bottom"},
		{"id":"47ad79b139446175","fromNode":"4922e102ab0aaee3","fromSide":"top","toNode":"06ec04552a1396c8","toSide":"bottom"},
		{"id":"cf302ae3009f670f","fromNode":"06ec04552a1396c8","fromSide":"right","toNode":"f4da95f68608e579","toSide":"top","label":"Reads that Node 1 is alive and well"},
		{"id":"111bb7a011b12a25","fromNode":"2fd6ef08a0eaf379","fromSide":"bottom","toNode":"42bbd39bf31360de","toSide":"top"},
		{"id":"1dc248fdc9ac175d","fromNode":"0277cd37f21bffd6","fromSide":"left","toNode":"2fd6ef08a0eaf379","toSide":"right"},
		{"id":"7e0248fa104e91fc","fromNode":"1411d43913cd79f5","fromSide":"left","toNode":"0cc94a2c81563b41","toSide":"right"},
		{"id":"bdc4df084733a529","fromNode":"0cc94a2c81563b41","fromSide":"bottom","toNode":"70e1a8ce9011dfdd","toSide":"top"},
		{"id":"6770847e0c223449","fromNode":"1411d43913cd79f5","fromSide":"bottom","toNode":"8bb0565ffdcdb731","toSide":"top"},
		{"id":"2f6e63370ceea6f2","fromNode":"70e1a8ce9011dfdd","fromSide":"bottom","toNode":"8bb0565ffdcdb731","toSide":"left"},
		{"id":"cda72436dde06e6c","fromNode":"69a7302eee11627d","fromSide":"right","toNode":"df15fa127fc1f609","toSide":"left","label":"Disconnected"},
		{"id":"c3613b91bd8f0526","fromNode":"1137a518da71369d","fromSide":"right","toNode":"1699ac8580e4fe9c","toSide":"left","label":"Crashed"},
		{"id":"214f2db101a064f3","fromNode":"7960fac0dd8f6e44","fromSide":"left","toNode":"b88209e3ccab92ec","toSide":"right"},
		{"id":"d97284a1e9e37b6b","fromNode":"7960fac0dd8f6e44","fromSide":"bottom","toNode":"913aa654aa19fb6e","toSide":"top"},
		{"id":"55bc4a3efc4cb0b2","fromNode":"b88209e3ccab92ec","fromSide":"right","toNode":"7960fac0dd8f6e44","toSide":"left"},
		{"id":"4944c849bd89bf53","fromNode":"913aa654aa19fb6e","fromSide":"top","toNode":"7960fac0dd8f6e44","toSide":"bottom"},
		{"id":"008c637f55b1db23","fromNode":"b88209e3ccab92ec","fromSide":"bottom","toNode":"913aa654aa19fb6e","toSide":"top"},
		{"id":"2521babb381ff046","fromNode":"913aa654aa19fb6e","fromSide":"top","toNode":"b88209e3ccab92ec","toSide":"bottom"},
		{"id":"1c9d362c25903622","fromNode":"60c4c1f763ae68ed","fromSide":"top","toNode":"03e41908a4234a94","toSide":"bottom"},
		{"id":"2d1b06855cbc62d4","fromNode":"8567620b43b17893","fromSide":"top","toNode":"60c4c1f763ae68ed","toSide":"bottom"},
		{"id":"f31469e903122d5b","fromNode":"03e41908a4234a94","fromSide":"right","toNode":"e25fd5be01c972eb","toSide":"top","label":"Reads that Node 1 is alive and well"},
		{"id":"33e88839a5d8094b","fromNode":"ebb2525c8336be83","fromSide":"right","toNode":"234d4aa4eb13fc73","toSide":"left","label":"TCP connection"},
		{"id":"de773e75c5f7d310","fromNode":"ebb2525c8336be83","fromSide":"right","toNode":"5e2768ae5ec70e72","toSide":"left","label":"Connection fail"},
		{"id":"f8fb97f1e0058ceb","fromNode":"ebb2525c8336be83","fromSide":"right","toNode":"cc5427e78474255e","toSide":"left","label":"Connection success"}
	]
}